\newpage

\begin{CJK*}{GBK}{song}

\setcounter{chapter}{3}
\setcounter{section}{0}

\chapter{受众定向}

\thispagestyle{empty}
\markboth{受众定向}{受众定向}

对于在线媒体上的显示广告和文字链广告，要提高其回报，受众定向是其最重要的核心技术。从计算广告的核心，即优化一组流量上的ROI这一问题的角度来看，受众定向技术即是对广告$(a)$、 用户$(u)$、上下文$(c)$ 这三个维度提取有意义的特征(这些特征也称为标签)的过程。我们说过，上下文标签可以认为是即时的用户兴趣，因此我们把他们统称为受众定向。受众定向虽然不见得是计算广告中最困难的技术，但是确实是在线广告、特别是显示广告最核心的驱动力。因此，我们将这一问题单独拿出来，用一章的篇幅做深入的探讨。

从第一章里介绍的广告有效性模型出发，可以对各种定向技术有原理性的把握。一般来说，对于某一种定向技术，我们需要同时关注其效果和量两方面的指标，同时提供覆盖率较高但精准程度有限的标签，和那些非常精准但量相对较小的标签，有利于市场形成竞争的环境，这也为后一章中讨论的竞价广告提供了基础。从技术框架的角度看，受众定向标签可以分成用户标签、上下文标签和广告主定制标签三种类型，其实现方案也有较大的不同。我们在本章中重点介绍前两种定向技术的做法，而广告主定制化标签属于需求方定义的标签，我们会在第七章中讲到DSP时再介绍。

上下文定向需要对广告所在的页面进行分析，然而这一分析过程与搜索引擎的爬虫有很大的不同。结合广告对上下文信息的需求特点，一般可以采用一种半在线的方式抓取和分析页面，我们也将会在本章中讨论这种方法的特点和优势。

行为定向是根据用户历史上的网络访问行为对用户打标签的过程。哪些网络行为会有价值，是我们在挖掘行为数据来源时需要考虑的问题。我们将列举一些业界公认的有价值的行为数据类型，并给出使用多种数据类型进行行为定向的基本框架。由于海量用户的原始网络行为的数据量一般来说特别巨大，如何设计非常高效的的数据组织方式，以及其访问流程，对于行为定向的实用化是非常关键的，这方面工业界的实践和经验总结，也是我们在本章涉及的一项重点内容。行为定向一般采用reach-ctr曲线进行半定量的评价，我们也会介绍这一曲线的用途和解读。

可以注意到，无论是上下文定向，以及在此基础上的行为定向，都广泛使用到文本分类和主题挖掘的技术。而在广告业务中，我们往往要选择那些有监督的主题挖掘方法，将页面内容映射到预先定义好的标签体系上，而不是无监督地自动聚类产生标签。这是由于广告中的标签体系要向广告主售卖，因此必须是可解释的。对于无监督和有监督这两种类型的的主题模型挖掘算法，本章中也做了概要的介绍，供大家在实际应用中参考。

本章还有一部分内容，是讨论广告业务中数据的核心作用，以及相应的产品和商业模式。熟悉了前面的受众定向技术，我们会发现，受众定向的的本质，是将用户在网络上的一些行为可以售卖的人群属性。这同时也揭示了精准广告业务的本质：将原材料，即用户行为数据，加工成标签，再将标签售卖给需要的广告主。而广告投放过程已经变成了交付这些标签的载体而已。既然数据加工本身如此重要，这足以成为互联网广告中相对独立的一项业务。于是，数据加工与交易的产品化和规模化，成为在线广告区别于传统广告的一项重要市场特点。在这样的环境下，数据管理平台(DMP)这样面向数据收集、加工和交易的产品也应运而生。有关DMP的功能和典型案例，我们在本章后半段也会讨论。

\section{定向方法综述}

随着在线广告技术和业务的发展，产生了各种各样的受众定向方法，这些方法的综合应用，使得广告的精准程度越来越高。在考察某种定向方法时，主要有两个方面的性能需要关注：一是定向的效果，即符合该定向方式的流量上高出平均eCPM的水平；二是定向的规模，即这部分流量占整体广告库存流量的比例。当然，效果好、覆盖率又高的定向方法使我们追求的目标，不过往往难以两全。因此，广告系统有必要同时提供多种定向方法的支持，以达到整体流量上质的最优化。

我们先来看一些市场上比较流行的定向方式。按照其有效性和在广告信息接受过程中起作用的阶段，对照第一章中的广告有效性模型，我们把这些定向方式按照非常粗略的定性评估表示在图\ref{fig_target}中：
\begin{figure}\label{fig_target}
\centering
\scalebox{0.6}
{
    \includegraphics[width=1.65\textwidth]{target.eps}
}
\caption{常见受众定向方法一览}
\end{figure}

在该图中，水平方向表示的是定向技术在广告信息接收过程中大致起作用的阶段，而垂直方向为大致的效果评价(越往下效果越好)。

总体上看，按照计算框架的不同，这些受众定向的技术可以分为三种类型：1. 用户标签，即可以表示成$t(u)$形式的标签，或者说是以用户历史行为数据为依据，为用户打上的标签；2. 上下文标签，即可以表示成$t(c)$ 形式的标签，或者说是根据用户当前的访问行为得到的即时标签；3. 定制化标签，即可以表示成$t(a,u)$形式的标签，这这是一种用户标签，不同之处在于是针对某一特定广告主而言的，因而必须根据广告主的某些属性或数据来加工。对受众定向的一些典型方法，我们举例说明如下：

一、\begin{CJK*}{GBK}{kai}地域定向(Geo-targeting)\end{CJK*}。这是一种很直觉、也很早就被广泛使用的定向方式。由于很多广告主的业务有区域特性，这种定向方式的作用相当重要，也是所有在线广告系统都必须支持的定向方式。地域定向也可以认为是一种上下文定向，不过由于其计算简单，仅仅需要简单的查表就可以完成，因而我们往往对其单列为一种定向方式。地域定向虽然一般来说效果有限，却是一种不可或缺的流量选择手段。举个例子，假设某电商网站只在北京运营和送货，那么其效果广告一般来说应该定向在北京的区域内，否则一个其他省的顾客点击广告进入购物环节后，如果发现无法结算，将会是非常差的用户体验。

二、\begin{CJK*}{GBK}{kai}人口属性定向(Demographical targeting)\end{CJK*}。人口属性定向虽然在普遍意义上效果并不算特别突出，但是由于这是线下传统广告比较常用的分析维度，因而在互联网品牌广告中比较早地被采用。人口属性的主要标签，包括年龄、性别、收入水平等。需要说明的是，除非有特别的专门数据来源，例如实名制SNS的注册信息或在线购物的消费记录等，一般情况下要进行准确的人口属性定向并不容易。在人口属性数据覆盖率不足的情况下，如果要按照这种定向进行CPM售卖，我们可以用已知人口属性的用户作为训练集，构造分类器对人口属性进行自动标注。一般来说，采用分类器的方法确定人口属性准确程度有限。在效果广告应用中，一般不需要这样做，因为预测出来的人口属性也是根据用户其他行为得到，因此对eCPM预测并不能提供额外的信息量。

三、\begin{CJK*}{GBK}{kai}频道定向(Channel targeting)\end{CJK*}。频道定向是完全按照供应方的内容分类体系，将库存按照频道作为划分依据，对各频道的流量投送不同的广告。这种定向方式比较适用于那些离转化需求比较近的垂直类媒体，比如汽车、母婴、购物导航等。对于内容覆盖面比较宽的媒体，这种方式很难取得的效果是有限的。举一个极端的例子，如果我们吧某网站的军事频道作为一个定向标签，那么很难找到直接匹配的广告需求。

四、\begin{CJK*}{GBK}{kai}上下文定向(Contextual targeting)\end{CJK*}。将频道定向这种方法加以推广，可以根据网页的具体内容来匹配相关的广告，这就是上下文定向。上下文定向的粒度，可以是关键词、主题，也可以是根据广告主需求确定的分类。上下文定向的效果在不同类别的内容上有很大的区别，但是这种方式有一个非常大的好处，那就是覆盖率比较高：对大多数广告展示，不论对当前访问用户的信息了解有多少，往往都可以根据当前浏览的页面推测用户的即时兴趣，从而推送相关广告。由于覆盖率高，上下文定向也是广告网络中首选的定向方法。

五、\begin{CJK*}{GBK}{kai}行为定向(Behaviorial targeting)\end{CJK*}。行为定向是显示广告中非常重要的一种定向方式，其框架是根据用户的历史访问行为，了解用户兴趣，从而投送相关广告。行为定向之所以重要，是因为它提供了一种一般性的思路，使得我们在互联网上收集到的用户日志可以产生变现的价值。因此，行为定向的框架、算法和评价指标，也就奠定了了在线广告数据驱动的本质特征，并催生了相关的数据加工和交易的衍生业务。如果我们把上下文定向看成是根据用户单次访问行为的定向，那么行为定向可以认为是一系列上下文定向的融合结果。因此，上下文定向是行为定向的基础，而且对各种类型的上下文定向，都可以有相对应的行为定向方式。例如，地域定向是根据用户当前访问的IP来确定地理区域，相应地，我们也可以根据用户过去一段时间内的访问中最频繁的地理位置来定向，这种方式实际上得到的跟接近于用户的经常居住地，业界有人称其为\begin{CJK*}{GBK}{kai}“Where-on-earth”定向\end{CJK*}。

六、\begin{CJK*}{GBK}{kai}精确位置定向(Hyper-local Targeting)\end{CJK*}。在移动设备上投放广告时，我们有可能获得非常精准的地理位置。比如利用蜂窝信息或者GPS，地理定位的精度完全可以达到街区的粒度。这就使得基于精确地理位置的广告成为可能，也使得大量区域性非常强的小广告主，比如餐饮、美容等有机会投放精准定位的广告，这已经与传统意义上的地域定向有了质的变化，也成为移动广告最重要的机会之一。在桌面环境中，也有的数据提供商，例如Experian，可以提供根据IP信息做的电脑精确定位，在这样数据的支持下，桌面在线广告也可以进行精确位置定向。

七、\begin{CJK*}{GBK}{kai}重定向(Retargeting)\end{CJK*}。这是一种最简单的定制化标签，其原理是对某个广告主过去一段时间的访客投放广告以提升效果。显然，某个广告主的访客是其独有的信息，因此这属于定制化标签。重定向各种定向方式中被公认精准程度最高、效果最突出的，不过其人群覆盖量往往也较小。这是因为，重定向的覆盖投放量是由广告主固有用户的量和与媒体的重合比例共同决定的。关于重定向的原理和技术，我们将在第八章中具体介绍。

八、\begin{CJK*}{GBK}{kai}新客推荐(Look-alike)\end{CJK*}。由于重定向的量太小，而且无法满足广告主接触潜在用户的需求，因此不能仅仅依靠它来投送广告。Look-alike定向的思路，是根据广告主提供的种子访客信息，结合广告平台更丰富的数据，为广告主找到行为上相似的潜在客户。这一方法的目的，是希望在同等用户覆盖比率的情况下，达到比一些通用的兴趣标签更好的效果，是Look-alike 所希望达到的，这也从实质上体现了广告主数据的核心价值。新客推荐只能说是一种大致的思路，而非具体的方法，其基本原理和做法，我们也将在第八章中介绍。

九、\begin{CJK*}{GBK}{kai}团购(Group Purchase)\end{CJK*}。这并不是一种定向广告技术，却与其有一定的关联，因此我们在这里一并说明。**************************

以上各种定向中，地域定向、频道定向和上下文定向属于$t(c)$的定向方式；人口属性定向、行为定向属于$t(u)$的定向方式；而重定向和Look-alike则是$t(a,u)$的定向方式。各种定向的标签被应用于根据用户和环境信息选取广告候选的过程，因而对广告投送的结果会有比较显著的影响。$t(c)$和$t(u)$两种定向方式，一个根据的是当前页面信息，一个根据的是历史日志数据，因而在系统框架上有比较大的区别。下面我们将对这两种方式的典型代表，即上下文定向和行为定向的实现进行讨论。**************************

\section{上下文定向}

我们先来看那些归类为$t(c)$的受众定向方式。这样的定向中有一些根据广告请求中的参数信息经过简单运算就可以得到，比如频道/URL定向，操作系统定向等；另外一类则是根据上下文页面的一些特征标签，比如关键词、主题、分类等进行定向，我们重点讨论这样的上下文定向技术。

我们先抛开标签体系不谈，仅仅从打标签的方法上来看，上下文定向主要可以有如下的几种思路：1. 用规则将页面归类到一些频道或主题分类，这种方法相对简单；2. 提取页面中的关键词，这种方法是将搜索引擎的关键词匹配技术推广到媒体广告上时自然产生的，也是上下文定向的基本方法；3. 提取页面入链锚文本中的关键词，这种方法需要一个全网的爬虫作支持，因此已经超出了一般意义下广告系统的范畴，有兴趣的读者可以参考搜索引擎方面的有关文献；4. 提取页面流量来源中的搜索关键词，这种方法除了页面内容，也需要页面访问的历史记录作支持，从技术方案上来看更接近后面介绍的行为定向；5. 用主题模型将页面内容映射到语义空间的一组主题上，这样做的目的是为了泛化广告主的需求，提高市场的流动性，这一类的方法将在下文专门介绍。

在以上各种思路中，关键词提取是一项基础技术。上下文定向中的关键词提取，可以按照信息检索中的一般方法，即选取页面内容中TF-IDF较高的词作为关键词(见第二章中的具体介绍)；也可以采用需求方驱动的思路，从广告商相关描述中得到商业价值高的关键词表和IDF，再与页面内容中关键词的TF一起计算TF-IDF，来选取关键词。当能够得到比较丰富的广告信息时，比如运营Adsense那样的文本广告，或者可以拿到广告主SEM(Search Engine Marketing)词表时，后一种方法往往更加有效。

确定了对上下文页面打标签的方法以后，在在线广告投放时，页面标签系统需要对Ad Server查询的某一个URL快速返回其对应的标签。复杂的打标签计算是不可能马上完成的，不过在广告的问题中，某一次展示时标签的缺失并不是致命性的。根据广告的这一特点，我们可以用一种半在线的方式来实现页面抓取和打标签的逻辑。

\subsection{半在线抓取系统}

上下文页面的有关信息显然不可能在广告请求发生时实时分析得到，那么我们是否需要一个类似于搜索引擎蜘蛛的系统来做预先抓取呢？对于广告系统来说，其实是没有这个必要的。因为页面信息对搜索引擎而言，是服务的主体内容，而对广告系统而言，只是锦上添花的补充信息，我们完全可以设计一个更轻量级，效率更高的页面抓取服务。这种页面抓取服务的关键，是不作任何离线抓取，而在在线服务时产生了实际需求后才尽快抓取，我们把它叫做半在线(near-line)的抓取系统。

下图概念性地表示了半在线抓取系统的工作原理。如图所示，系统用一个cache服务来保存每个URL对应的标签，当在线的广告请求到来时：一、如果该请求的上下文URL在cache中存在，那么直接返回其对应的标签；二、如果该URL在服务中不存在，为了广告请求能及时得到处理，我们就马上返回空的标签集合，同时马上往后台的抓取队列中加入此URL，这样在较短的一段时间(通常为秒至分钟量级)之后，该URL就被抓取下来，并打上标签存入cache中。考虑到页面内容可能会不定期更新，我们可以设置cache合适的TTL(Time To Live)以做到自动更新标签。半在线抓取系统的示意见图\ref{fig_context}。

\begin{figure}
\centering
\scalebox{0.6}
{
    \includegraphics[width=1.5\textwidth]{contextual.eps}
}
\label{fig_context}
\caption{上下文定向半在线抓取系统示意}
\end{figure}

这样的方案，有以下的两点好处：首先是在线cache的使用效率非常高，仅仅那些最近有广告请求的发生的URL才会被抓取，这样我们不需要耗费大量的爬虫资源去抓取可能根本用不到的页面。其次，因为我们只抓取需要的页面，并且可以在该页面第一次广告请求后很快得到页面标签，页面的信息覆盖率也很高。

\section{行为定向}

再来看那些归类为$t(u)$的受众定向方式。这样的定向可以分为两类：一类也是根据广告请求中的某些信息经过简单运算就可以得到，比如地域定向；另外一类则需要大量的历史数据挖掘才能得到，我们重点讨论这一类定向技术的实现方案。这类定向问题包括从用户网上浏览记录加工得到的兴趣定向，以及根绝用户历史所在的地域得到的用户主要居住地的"where on earth"定向等。由于这种定向都是根据用户的历史行为进行挖掘的问题，我们把它们统一称为\begin{CJK*}{GBK}{kai}行为定向(behaviorial targeting)\end{CJK*}。

行为定向的目的，是把用户的线上或线下行为映射到对广告主有意义的标签体系上。行为定向的标签体系有两种组织方式：一种是按照某个分类法(Taxonomy)制定一个层次标签体系，其中上层的标签是下一层的父节点，在人群覆盖上是包含关系。一些面向品牌广告的受众定向，往往采用这种结构化较强的标签体系，比如Yahoo!的GD广告体系中的行为定向体系，其标签分为多个层次，其中前两层的一部分标签如下所示：

\textbf{Finance} - Bank Accounts, Credit Cards, Investiment, Insurance, Loans, Real Estate, ...

\textbf{Service} - Local, Wireless, Gas \& Electric, ...

\textbf{Travel} - Europe, Americas, Air, Lodging, Rail, ...

\textbf{Tech} - Hardware, Software, Consumer, Mobile, ...

\textbf{Entertainment} - Games, Movies, Television, Gambling, ...

\textbf{Autos} - Econ/Mid/Luxury, Salon/Coupe/SUV, ...

\textbf{FMCG} - Personal care, ...

\textbf{Retail} - Apparel, Gifts, Home, ...

\textbf{...}

\textbf{Other} - Health, Parenting, Moving, ...\\
需要指出，这一体系中的标签，是根据需求方的逻辑而制定，某些在媒体方意义很大的分类标签，比如军事等，由于没有明确的需求对应，不宜直接出现在标签体系中。对这样的媒体上的用户，应该用受众定向的方法根据其用户的细分特征映射到上面需求方的标签体系中。

另外一种标签的组织方式，是根据广告主某类特点的定向需求设置相应的标签，所有的标签并不能为同一个分类体系中所描述，也不存在明确的父子关系。这种半结构化的标签体系，往往包含一些比较精准的标签的集合，因而主要适用于多种目标、特别是效果目标并存的广告主的精准流量选择要求。关于这种标签体系，比较典型的是Bluekai采用的标签体系，我们会在后文中再做介绍。

行为定向是精准广告业务中对数据利用和变现最重要的问题，这一问题可以描述如下：

\begin{CJK*}{GBK}{kai}行为定向，是根据某用户一段时期内的各种网络行为，将该用户映射到某个定向标签上。\end{CJK*}

哪些行为会对定向有所贡献呢？互联网广告业界经过探索，对此问题有一些共同的认识。一般来说，有九种行为是确定对行为定向的建模有意义的。在评价某种行为的作用时，主要关注两个因素，一是质，就是上面所说的信息强度，二是量，就是该行为的频繁程度。我们按照这些行为的信息强度和性质，将这些行为分为四组排列如下：

一、决策行为：转化(Conversion)、 预转化(Pre-conversion)。这些指的是在广告主的网站中发生的行为，往往对应着非常明确的用户兴趣。比如在电商网站上，转化就对应着最后的下单，而预转化对应下单前的搜索、浏览、比价、加入购物车等多种准备工作。这类行为的价值是最高的，但是也是供给方最难得到的。根据广告主端的数据来进行重定向或者个性化重定向是对此类行为最直接的利用，当然，在行为定向中，这类数据虽然量不大，但却不能忽视。

二、主动行为：搜索广告点击(Sponsored search click)、广告点击(Ad click)、 搜索点击(Search click)、 搜索(Search)。这一组行为都是用户在网络上在明确意图支配下主动产生的行为，因而也有比较丰富的信息量。其中的几种广告点击行为一般来说量不大，并不能作为定向的主要数据来源。而搜索行为是能够大量获得的最主要的
主动行为，需要特别注意挖掘利用。

三、半主动行为：分享(Share)、 网页浏览(Page View)。这两类行为都是用户在目的比较弱的网上冲浪过程中产生的。因此，其所设计的兴趣领域对把握用户信息有价值，但是非常细节的内容则精准程度有限。**********************************

四、被动行为：广告浏览(Ad view)。广告浏览严格来说不能算作定向的行为依据，但是由于其频次与相应类别的广告点击负相关，因而在行为定向的建模中也可以使用。

从目标的角度来看，行为定向问题的目标是找出在某个类型的广告上eCPM相对较高的人群。如果进一步假设在该类型的广告上点击价值近似一致，那么问题就转化为找出在在该类型广告上点击率较高的人群。虽然我们说过，对品牌广告而言，点击率未必总是合理的评价指标，然而当我们认为在该类型上的各种广告目的均衡存在时，点击率仍然具有相对的衡量意义。因此，我们可以把某个用户在某类广告上的点击数目作为建模的对象。

由于点击行为是离散到达的随机变量，对其数目最自然的概率描述是泊松(Poisson)分布。泊松分布的形式如下：
\begin{equation}\label{BT}
p(h) = \frac{\lambda^h \exp(-\lambda)}{h!}
\end{equation}
其中$h$为某个用户在某个定向类别广告上的点击数目\footnote{在文\cite{Chen}中，展示数目也被用一个用历史行为决定参数的泊松分布来建模，我们认为，广告并非用户主动行为，因此不宜用历史行为来预测。}，而$\lambda$即位控制点击行为到达频繁性的参数，我们的模型应该做的就是把用户的行为与此参数联系起来。如果我们利用线性模型联系用户行为和$\lambda$，则有：
\begin{equation}\label{BT_linear}
\lambda = w_l^\top x_l(b)
\end{equation}
这里的$w$即为受众定向模型的需要优化的参数矢量。这里我们将原始行为$b$先经过一个与标签$l$相关的特征选择函数，以得到与此类别相关的evidence，再将此evidence作为特征用在上述模型中。将式\ref{BT_linear}代入式\ref{BT}，就得到行为定向的整体模型。

上面是一种非常典型的工程建模思路：当我们面对一个多自变量的回归问题时，可以现根据目标值的特性选择合适的指数族分布来描述，并用线性模型将多个自变量和指数族分布的参数联系起来。这样做，可以利用线性模型更新简单和可解释性强的特点，同时又对目标变量的类型有较强的适应性。这种建模方法，称为广义线性模型(Generalized Linear Model, GLM)。有关广义线性模型的一般性讨论，请大家参看[]。

公式\ref{BT}的行为定向模型，有几点需要注意：首先，$w$ 可以是与标签$l$相关的，即对不同的定向标签训练不同的线性函数。这样做的优点是可以更准确地对每个类别进行建模，但缺点是当有些类别数据不足时估计偏差较大。当$w$ 与标签相关时，原始行为也可以不经过特征选择函数，或者经过一个与标签无关的选择函数，这是因为类的本质特征已经反映在了对行为进行映射的参数矢量上。其次，就这种建模方法来说，主要适用于有明确需求方意义的标签体系。因此只有广告上有这些标签，才能根据其点击行为来建模。就模型的线性形式来说，在一些按供给方逻辑定义的标签体系上，也可以用类似的行为加权和的形式来进行定向。然而，此时其权重参数的确定无法利用相应的广告点击作指导，不过仍然可以借用其他需求方标签体系的训练结果。

上面的行为定向模型特征生成的过程，由于样本量比较大，需要有一个比较高效的方法来简省计算量，我们在下面具体讨论。

\subsection{行为定向特征生成}

关于行为定向特征的生成，需要讨论两个方面，一是特征选择函数$x_l$的确定；二是模型\ref{BT}训练集的组织和生成方式，这两方面都对计算性能有着巨大的影响。由于行为定向是在线广告计算问题中数据规模最大的，处理的高效性是我们在工程中主要考虑的问题。

我们常用的特征选择函数，是将每一类用户用户行为先分别映射到标签体系上，再计算出各个行为在某个标签上累积的强度作为模型的特征输入。例如，对于页面浏览行为，我们向上下文定向中介绍的那样，将页面内容转换为标签，作为此次行为的标签；而对于搜索行为，我们可以根据查询词将其映射到某些标签上，在将某个用户在一段时间内在标签$l$ 的查询词总数，作为$x_l$ 里的一维。这里要注意的关键，是“一段时间内的行为”，因为过于久远的行为对于用户兴趣的贡献是很小的。如何将行为累计控制在一段时间以内，工程上有两种常用的方法，分别是滑动窗法和时间衰减法，我们用图\ref{fig_decay}来示例：
\begin{figure}
\centering
\scalebox{0.6}
{
    \includegraphics[width=1.0\textwidth]{decay.eps}
}
\label{fig_decay}
\caption{用户行为累计方法示意：上、滑动窗法；下、时间衰减法}
\end{figure}

在滑动窗法中，我们设定一个窗长$T$，然后将从当前时间倒推再此窗长内所有属于$l$的行为强度累加起来；而在时间衰减法中，我们并不明确设定窗长，而是转而设定一个衰减因子$\alpha_l$，然后用累积到上一个时间片的特征$x_l(t)$与本时间片的行为强度$b_l(t)$递归地得到今天的特征$x_l(t+1)$，其递归更新公式为：
\begin{equation}\label{linear}
x_l(t+1) = \alpha x_l(t) + (1-\alpha)b_l(t)
\end{equation}
这两种方式并无本质上的区别，其实际对原始行为过滤的窗型，前者为矩形，后者为指数形，并且形状都由唯一的参数来控制。但是从工程角度看，我们更推荐使用第二种方案，因此在这种方法中，只需要保存累积到前一个时间片的特征和当前时间片的行为强度，空间和时间复杂度都较低。

行为定向的训练过程，实际上就是调整各个标签类别上各种特征权重的过程。影响训练结果的有两个主要的因素：一是训练集的长度。由于上述的时间因素的影响，我们准备的训练集需要横跨若干天的范围，一般来说，为了消除星期这一显而易见的周期性影响，这一天数可以选择为7的整数倍。对一个用户来说，他前一天的行为特征$x_l(t)$，和当天的该标签广告点击次数$h_l(t)$，对应于\ref{BT}的一个训练样本。因此，每个用户实际上会生成多个训练样本。二是时间片的大小。这实际上反映了我们对定向的时效性的要求：如果我们希望更快地利用行为信息对定向标签做出调整，必然要缩小这一时间片大小\footnote{更快地利用用户行为反馈还有其他系统方面的需求，请参见第7 章中``短时行为反馈"一节。}。可以想见，训练集的样本数目，正比于训练集长度，且反比于滑动时间片长度。当用户数目较多、训练集长度较长、而滑动时间片又较短时，总的训练样本数目是很大的。

为了避免计算冗余，使得训练时的空间代价尽可能地小，在\cite{Chen}中，作者给出了一个复杂度为$O(1n)$的训练样本生成算法，该算法的关键点，是将同一个$u$的所有行为都一次性加载到内存中，并按时间顺序排列成一个事件流。通过在此事件流上向前滑动，依次得到各个$(u,t)$对应的训练样本。另外，在一个滑动时间片内的事件，已经预先按照我们需要的粒度聚合成一些计数，这些计数是生成特征的基础。如果我们采用上文中滑动窗法的特征选择函数，那么需要保留前$T$个时间片的行为事件，并生成相应的训练样本。这一方法看起来非常普通，确实在大规模用户行为分析时必须要注意的，也是我们在计算广告架构(图\ref{Arch})中Session Log部分设计的原则，即一定要将所有用户日志预先组织成以用户ID为key的统一格式。我们将行为定向特征生成算法的示例性代码列在下面：
\begin{lstlisting}[language={C++}]
int bt_sample_gen(vector<vector<float> > & events, int T,
                  vector<vector<float> > & features,
                  vector<vector<float> > & targets)
{
  int numSlice = events.size();
  int dim = events[0].size();

  features.resize(numSlice);
  features[0] = events[0];
  for (int s = 1; s < numSlice; s ++)
    {
      features[s] = features[s - 1];
      for (int d = 0; d < dim; d ++)
        {
          features[s][d] += events[s][d];
          if (s - T >= 0)
            features[s][d] -= events[s - T][d];
        }
    }
}
\end{lstlisting}
如果采用衰减因子的特征选择函数，则程序将更加简单，并且可以改成串行处理方式，即每次输入一个时间片的行为事件，同时输出当前的特征。

采用这种方案，我们只需要将各个时间片的原始行为和target值保存在持久化存储中，而在训练过程中on-the-fly生成实际的训练样本。由于考虑到用户的上网行为从时间段上来说一般具有很强的局部性，这样的做法可以避免为了生成训练样本而带来的冗余存储，同时引入的额外计算量也很少。

\subsection{行为定向参数更新}
得到了训练样本以后，我们需要用其更新\ref{BT}中的行为定向参数。如果行为定向的模型属于指数族分布的范畴，比如线性回归(Linear Regression)模型，那么只需要对数据遍历一次，就可以得到最大似然解。不过对于公式\ref{BT}中的模型形式，则需要多次访问数据迭代求解。由于上面介绍的特征生成过程是on-the-fly生成特征，我们需要给出在生成了特征后需要累积的统计量，以及在统计量收集完成后模型参数更新的公式。

根据\cite{Chen}中的讨论，**********************************

\subsection{行为定向的评测}

对于上面讨论的行为定向模型，其效果并非是一个确定不变的值，这是因为我们可以通过调整线性函数\ref{linear}的阈值来控制某个标签人群的量，当然在量扩大的情况下一般来说精准性也会降低。对其他形式的行为定向模型，也都具有类似的特点。因此，行为定向模型的评测，需要考虑到量的影响。一般来说，我们可以通过Reach-CTR曲线来进行半定量的评测。在正常情况下，较小的人群规模应该较为精准，也即对该类型广告的CTR较高，而随着人群规模的扩大，该CTR 也会逐渐走低。我们把标签接触到的人群规模称为reach，而这一reach 和CTR 构成的曲线，是评价该标签上的定向是否合理，以及效果如何的重要依据。
\begin{figure}\label{fig_reachctr}
\centering
\scalebox{0.6}
{
    \includegraphics[width=0.9\textwidth]{reachctr.eps}
}
\caption{Reach-CTR曲线示意}
\end{figure}

我们在图\ref{fig_reachctr}中给出了reach-CTR曲线的一个示例，我们来了解一下读这个曲线的几个关键点。首先，该曲线应该大体上呈下降的趋势，如果数据质量或定向建模有一些问题，有时会出现非下降的趋势，或者头部较低的情况，这意味着调低用户规模反而使得点击率下降，这显然是不正常的。如果出现这种情形，则需要特别引起注意，认真检查定向流程，或者判断是否已有的数据无法支持该定向标签。其次，reach-CTR曲线最右端一个点的CTR水平是固定的，既无法通过改善数据和模型来提高的，因此这是reach达到100\%，也即全部用户的情形下的CTR水平。而该曲线的斜率越大，往往表示定向模型的鉴别力越强。由于实际中一般会将阈值设定得较高，从而达到较好的定向效果，因此我们往往只需要关注该曲线头部的部分即可。

工程中需要注意的是，生成reach-ctr曲线的过程，需要仅仅访问一遍数据就能够完成。因此，我们在前面受众定向的过程中，需要保留的是每个用户在各个标签上的得分值，而不是最后二员的判断结果。给定一批测试用户在所有标签上的定向得分值，生成reach-ctr曲线的过程如下面的代码所示：
\begin{lstlisting}[language={C++}]
int reach_ctr()
{
}
\end{lstlisting}

\section{文本主题挖掘}\label{sec_topic}

从上面两种定向的讨论可以知道，对页面的分析和标签化是一项基础工作。页面打标签的粒度，可以精细到关键词，也可以粗略到页面的类型。除了这两种极端情况，我们也可以考虑将页面内容直接映射到一组有概括性意义的主题上，比如将一个讲编程语言的博客页面映射到“IT技术”这样的主题上。如果把页面视为一个文档，这就对应于主题模型(Topic model)的研究问题。总体上看，主题模型有两大类别：一种是预先定义好主题的集合，用监督学习的方法将文档映射到这一集合的元素上；一种是不预先定义主题集合，而是仅仅控制主题的总个数或聚类程度，用非监督学习的方法自动学习出主题集合，以及文档到这些主体的映射函数。广告中的主题挖掘有两种用途：如果仅仅用于广告效果优化的特征提取，那么监督或非监督的方法都可以；如果是用于建设对广告主售卖的标签体系，那么应该优先考虑采用监督学习的方法，因为这样可以预先定义好对广告主有意义且可解释的标签体系，对后续售卖会有很大帮助。

\subsection{无监督主题模型}

为了理清主题模型发展的技术脉络，我们先从非监督方法介绍起。先来看一下问题的描述：假设我们有一个由$M$个词组成的词表，以及一组文档$\{d_1, d_2, \cdots, d_N\}$，采用“bag of words”表示，文档$d_n=\{x_{n,1},x_{n,2}, \cdots, x_{n,M}\}$ $(1 \leq n \leq N)$的形式，其中$x_{n,m}$为词表中第$m$个词在$D_n$ 中对应的词频或TFIDF值。显然，一般情况下，矩阵$X=\{x_{nm}\}_{N\times M}$是非常稀疏的。假设这一文档集合主题模型对应着$\{1, 2, \cdots, T\}$这一组主题，我们的目的就是对每个文档得到其在这些主题上的强度$T_n=\{z_{n,1},z_{n,2}, \cdots, z_{n,T}\}$ $(1 \leq n \leq N)$。

\subsubsection{LSA模型}

这一问题最初的解决思路，是对上面文档和词组成的矩阵进行奇异值分解(Singular Value Decomposition, SVD)，找到这一矩阵的主要模式，这一方法称为潜在语义分析(Latent Semantic Analysis, LSA)。LSA的方法可以表示如下：
\begin{equation}
\{X\}_{N\times M} = (\alpha_1 \cdots \alpha_K) \cdot \textrm{diag}(s_1, \cdots, s_K) \cdot (\beta_1 \cdots \beta_K)^\top
\end{equation}
其中$K$为矩阵$X$的秩，$s_1 \geq s_2 \cdots \geq s_K$为$X$的K个奇异值。左侧的矩阵就是将潜在语义空间中的主题映射到某个文档的变换矩阵，而右侧的矩阵则是主题映射到某个文档词表中某个词的变换矩阵。我们最多可以得到的潜在语义主题数目，等于矩阵$X$的秩$K$，不过一般情况下，我们都会选择一个远小于$K$的主题数目用来描述整个语义空间。当我们选择的主题数目为$K$时，实际上是用下式对$X$进行了近似：
\begin{equation}
\{X\}_{N\times M} \thickapprox (\alpha_1 \cdots \alpha_T) \cdot \textrm{diag}(s_1, \cdots, s_T) \cdot (\beta_1 \cdots \beta_T)^\top
\end{equation}
这等价于我们令所有的$s_t(T < t \leq K)$都等于0，换句话说，通过这种方式去掉了大多数非主要因素的影响，从而得到了整个语义空间比较平滑的描述，相应得到的文档主题，比起关键词特征来，也就具有更好的的泛化能力。

根据奇异值的特性，我们知道所有的奇异值都是非负的，但是LSA得到的两个变换矩阵，不能保证每个元素都为非负值。这一点对应的直觉意义是：如果一篇有某个主题的话，可能该文档中出现某些词的频次的期望值为负。这一点，直观上并不十分容易理解，是LSA模型与后面几种概率文档主题模型不太一样的地方。

\subsubsection{PLSI模型和GaP模型}

LSA方法的物理意义清楚，也有成熟的数学工具可以利用，因而在信息检索中得到了比较早的应用。类似的思想也可以用概率建模的方式来表达。概率的方法，是通过对文档生成的过程进行建模，来进行主题分析。这一生成过程可以表达为：

1. 每个文档$d$对应一个topic的Multinomial分布$p(z | d)$，据此生成一个主题$z_i$；

2. 给定主题，对应一个词的Multinomial分布$p(w_n | z_n, \beta)$，据此生成一个词$w_i$；\\
其中的参数$\beta = (\theta_1, \cdots, \beta_K)^\top$，而$\beta_k$即为$P(w|z_k)$对应的Multinomial分布的参数。这一模型称为PLSI(Probabilistic Latent Semantic Indexing)\cite{Hofmann}。 对应于上面的生成过程，矩阵$Z$ 的生成似然值可以表达为：
\begin{eqnarray}
\log P(Z) &=& \prod_n P(d_n) \prod_m \sum_z P(z|d_n) P(w_m|z)^{x_{nm}}  \nonumber \\
          &=& \prod_n \prod_m \sum_z P(z) P(d_n|z) P(w_m|z)^{x_{nm}}
\end{eqnarray}

PLSI从字面上看，是概率化了的LSA模型，我们可以将$P(d_n|z)$和$P(w_m|z)$分别对应于LSA中的两个变换矩阵。不过这两个模型的物理意义也有所不同：在PLSI中，由Multinomial分布的定义我们知道，变换矩阵即两个条件分布的元素都大于0，也就是说给定一个主体的情况下，某个词的词频的期望值不可能为负，这一点与直觉更为吻合，也是此概率框架合理性的表现。当然，实用中的效果根据数据集特性的不同，PLSI和LSA各有长处。

概率模型的另一个好处，是我们可以直接套用概率模型典型更新方法，并很容易地实现分布式求解。很容易看出，PLSI模型实际上是前文介绍的指数族混合分布的特例，其中的component 为Multinomial 分布。因此，可以直接套用EM算法，以及其对应的map/reduce或MPI迭代解法来解此问题。而前面的LSA模型用到的SVD分解，则需要一定的技巧才能变成分布式实现的版本，并且远没有EM算法的概念清晰和实现简单。因此，在实际的海量数据上的文档主题模型，PLSI比LSA有一定的实用优势。

PLSI模型用Multinomial分布来描述主题的分布和每个主题中的词分布，而Multinomial分布的特点是只考虑各个变量的相对比例，而不考虑其绝对数值。如果我们采用Gamma-Poisson过程来建模，即假设每个主题生成的概率用独立的Gamma分布来描述，而每个主题中某个词的产生服从Poisson分布，这就对应了Gamma-Poisson(GaP)模型\cite{Canny}。GaP模型与PLSI模型，如果从变量的依赖关系上看，是非常相似的，只不过两者具体条件分布的形式是不同的，而这种不同也是在通过在指数族中选取不同的分布而得到的。认真比较这两种文本主体模型的联系和区别，对于理解图模型表达的变量依赖关系和分布的具体形式在建模中的作用，有很大的帮助。GaP与PLSI 相比，由于没有将每个文档中各个主题变量的强度进行归一化\footnote{请注意，多维Gamma分布随机变量在归一化以后服从Dirichlet分布，也就是Multimonial分布的共轭先验形式。}，因而对内容相似的长文本和短文本的概率描述是不同的，而后续的Poisson词产生概率也更加适合离散到达时事件的描述，因而在文本主题建模上有一定的合理性。不过，GaP模型的EM最大似然解法不像PLSI那样有简单的闭式更新公式。在\cite{Canny}中，作者也是采用一种近似的方法来优化，因此，这一模型在工程中的实用性受到了一定的限制。

\subsubsection{LDA模型}

第二章讨论的贝叶斯方法，也可以应用于PLSI模型。这样做的动机，是在当文档信息不足或者噪声较大时，能够利用贝叶斯的框架对结果做有效的平滑。在贝叶斯框架下，我们视为上述PLSI模型的参数$\theta$为随机变量。对于某一篇文档，其生成过程可以描述为先验分布：

1. 根据分布选择文档长度$N$；

2. 根据$w$的先验分布$\textrm{Dir}(\alpha)$生成$w$；

3. 对每个文档中的词$n\in \{1, \cdots, N\}$：(a) 根据$\textrm{Multi}(w)$分布选择一个主题$z_n$；(b) 2. 给定主题，对应一个词的Multinomial分布$p(w_n | z_n, \beta)$，据此生成一个词$w_n$；

把这一生成过程与PLSI相对比可以知道，这相当于PLSI的贝叶斯版本，即给topic的分布$w$加上了先验分布，而先验分布采用的是共轭形式即Dirichlet分布。其对应的图模型见\ref{fig_LDA}。从第二章中的介绍可知，我们可以采用经验贝叶斯的方案来确定这两个先验分布，这样的模型就是LDA。由PLSI模型到LDA 模型，对文档生成过程的描述更为清晰，而根据贝叶斯学习的一般目的我们可知，LDA模型在数据噪声较大，或者每个文档内容较少时可以达到比较稳健估计的效果。
\begin{figure} \centering
    \setlength{\unitlength}{0.7mm}
    \begin{picture}(170,28)
    \thicklines

    \scaleput(40, 15){\bigcircle{6}}
    \put(39, 8){$\boldsymbol \beta_k$}

    \drawline(43, 15)(67, 15)
    \drawline(63, 14)(67, 15)(63, 16)

    \scaleput(70, 15){\bigcircle{6}}
    \put(68, 9){$\boldsymbol x_n$}

    \drawline(73, 15)(97, 15)
    \drawline(77, 14)(73, 15)(77, 16)

    \scaleput(100, 15){\bigcircle{6}}
    \put(99, 8){$\boldsymbol z_n$}

    \drawline(103, 15)(127, 15)
    \drawline(107, 14)(103, 15)(107, 16)

    \scaleput(130, 15){\bigcircle{6}}
    \put(129, 8){$\boldsymbol w$}

    \put(61,5){\framebox(56,19){}}
    \put(111, 6){$M$}

    \put(28,4){\framebox(26,19){}}
    \put(49, 5){$K$}

    \drawline(133, 15)(157, 15)
    \drawline(137, 14)(133, 15)(137, 16)

    \scaleput(160, 15){\bigcircle{6}}
    \put(159, 8){$\boldsymbol \alpha$}

    \put(58,0){\framebox(86,28){}}
    \put(139, 1){$N$}


    \end{picture}
\caption{LDA概率图模型表示}\label{fig_LDA}
\end{figure}

如果采用经验贝叶斯的方法来确定超参数$\alpha$，那么此时原来的参数$w$就变成了隐变量，优化的参数除了$\alpha$，还包括$\beta$，优化的目标函数可以写成：
\begin{equation}\label{lda-opt}
    p(w | \alpha, \beta) = \int p(w|\alpha)\left(\prod_{n=1}^N \sum_{z_n} p(z_n | w)p(w_n|z_n, \beta\right)
\end{equation}
由于PLSI 模型不是指数族分布，因而其对应经验贝叶斯模型的解不能通过*的EM 方法得到，而是需要采用变分法近似求解。在\cite{Blei} 中，对这一模型的变分解法进行了详细的介绍，大家可以参照。不过在实际的工程实践中，LDA 模型更为常用的更新方法是吉布斯采样(Gibbs Sampling) 法。

\subsection{有监督主题模型}

由于售卖的需求，广告中的受众定向标签体系有时是预先定义好的，有监督的主题模型对于广告问题来说更加适用。根据前文的讨论，它可以是一组非结构化的标签集合，也可以是一个结构化的层次标签体系。因此，我们有两种思路来解决此问题：一是采用Multi-label Classification的方法，二是沿用上面的主题模型方法，将其变成有监督主题模型。关于有监督主体模型，以上述的LDA 为出发点，研究者也提出了若干种相关的方法。

结合广告定向的情景，有两种有监督主题模型可以关注：一、sLDA(Supervised LDA)，这是在某种标签监督下进行主体挖掘的通用模型，适用于标签为各种分布的情形。当标签为离散值时，就对应于根据某种分类进行主题挖掘。二、HSLDA(Hierarchically-supervised)。在此模型中，标注的类型是一个Hierarchy上的层次标签，这非常切合于广告中的需求。

值得注意的是，在文档主题挖掘领域，还有一类方法也与Hierarchy有关，比如HLDA或HDP，但是其问题定义是在某个数据集上学习得到一个Hierarchy结构，而不是根据一个给定的Hierarchy上的标准挖掘潜在主题。因此，这类工作不属于有监督主题模型的范畴。

\section{数据加工与交易}

要提高定向的精准程度与人群覆盖率，技术并不是最重要的因素。那么什么才是决定性的呢？其实是数据的来源与质量。这是正确认识精准广告业务非常重要的观念。为了进一步强调这一观念，我们以大家更容易理解的石油加工工业为例与作类比：在石油工业中，从油田挖掘出的原油是整个行业的原材料，炼油厂的作用是把这一原材料加工成能直接做燃料用的汽油等商品，再输送给加油站这样的销售终端。在精准广告中，可以把用户的行为类比于石油工业中的原材料，而日志收集和清洗系统的作用就相当于油田的挖掘设备。而受众定向的平台，就可以类比于炼油厂，它把原油，即清洗过的日志，加工成用户标签，而这些用户标签就像汽油一样，是可以被销售和使用的了。而传统广告中起关键作用的广告位，在这里仅仅变成了加油站，负责完成产品消费的过程而已。

那么我们如何正确认识技术在精准广告业务中的作用呢？从上面的类比可以看出，技术的地位相当于挖掘设备和炼油设备，当然有着无可置疑的重要性。技术能力的高低，直接影响着数据采集和变现的有效性。不过从另一个角度说，技术的作用也不能被过分夸大。巧妇难为无米之炊，没有了高质量的原材料，即用户数据，再高明的技术也是没有用武之地的。

既然数据本身有这么根本性的作用，从某种意义上实际上是精准广告市场的核心，那么围绕数据本身的加工与交易，就与广告的投放技术一样令人瞩目。有哪些数据是对精准广告业务有直接贡献的呢，我们可以按照下面的分类来总结：

一、用户标识。对广告而言，如果标定哪些行为来自于同一个用户，是非常关键的问题。不管你能拿到多少访问日志，如果没有办法把它们跟你的投放系统联系起来，这些数据都没有办法发挥作用。对于浏览器行为，我们最常使用的用户标识是cookie，但是由于存在同时使用多个浏览器，cookie过期，或用户主动清除cookie的情况，这种用户标识的长期一致性并不算太好。不过好在对广告来说，起关键作用的还是用户近期内的行为，所以用cookie作用户标识还是有效且为业界广泛采用的基础方案。如果运营广告业务的域名同时提供其他有永久身份的服务，比如email、SNS等，那么可以用这一永久身份找回过期或被清除的cookie，这样用户身份的上一致性就会有所改善。当然，如果广告业务域名和用永久身份服务的域名不同，也不是完全没有办法，在后者同意的前提下，可以采用一种cookie映射的方法来对应彼此的用户身份，这一点的细节我们在后文谈到广告交易平台时再讨论。因此，高质量的用户标识，本身就是一种非常有价值的数据，也是可以在市场交换和售卖的。

二、用户行为。业内通常认为，主要有以下几种类型的在线行为是可以被广泛采集，且对于受众定向或广告决策有明确作用的：转化(transaction)、预转化(pre-transaction)、搜索广告点击(sponsored search click)、显示广告点击(ad click)、搜索点击(search click)、搜索(search)、分享(share)、页面浏览(page view)、广告浏览(ad view)。按照对效果广告的有效性，这些行为可以分为三档：第一档是转化与预转化行为，转化指的是在需求方网站上的具体决策步骤(例如电商的购物行为，游戏的充值等)，预转化指的是以及转化前的一些准备动作，比如浏览、搜索等。这两种行为由于直接明确反映了用户兴趣，因此信息有效性远远高于其余行为。第二档是搜索广告点击、显示广告点击、搜索点击和搜索，这些行为虽然离转化稍远一些，但是也基本属于用户主动行为，有效性也较高。最后一档是分享、页面浏览和广告浏览，这些行为往往都产生于用户在网上无目的浏览时，因此有时不能代表其真正意图，其中分享的有效性好一些，而广告浏览则是与效果负相关的――看得次数越多，效果越差。一般而言，越靠近转化的行为，越主动的行为，对受众定向的指导性越强。

三、人口属性。人口属性本身是常用的一种定向标签，因此其数据来源很重要。一般来说，只有一些能够与用户实名身份绑定的服务可以得到此信息。我们也可以利用网络行为数据来进行人口属性标签的预测，但是这样做的准确程度一般来说很有限，而且这仍然需要一些标定的数据用于训练。对于某些人口属性，可能一些特别的信息比较容易给出准确的判定，比如用语音服务记录的声音信号，可以将男女区分得相当准确。

四、地理位置。地理位置信息随着能获得的精度不同，其用途也会有相当大的差异。如果只能根据IP进行映射，我们往往只能拿到精确到城市级别的地理位置，当然这对于很多广告投放来说，已经有有相当的价值。而在移动互联环境下，GPS或蜂窝可以提供的定位往往可以准确到几百米的范围，这就使得Hyper-local的区域广告商投放定向广告成为可能。这样的广告定向，对于餐饮等受地理位置限制极大的线下业务广告商是非常有价值的。

五、社交关系。社交关系数据的主要意义，在于为用户属性和行为标签提供了平滑的可能性。这一方法的假设是同一个小圈子的用户可能在某些方面有相同的兴趣，因此受众定向可以转化为对这个小圈子共性的挖掘。从这个意义上来看，强关系类型的SNS比弱关系的有优势，关注人群比被关注人群的信息意义更大。

\section{数据理平台}

既然数据的收集和加工是广告市场上非常重要的环节，也就产生了专从事这方面业务的产品，称为数据管理平台(Data Management Platform, DMP)。它的主要功能，是逻辑聚合各种来源的在线的用户行为数据，按照需要方需要的加工成有价值的用户标签，然后在广告市场上使用这些标签来变现。

DMP有几个核心功能。一、它可以为网站(可以是媒体、也可以是广告主网站)提供受众定向功能，并将得到的用户标签应用于网站业务。在这一过程中，除了加工一些通用标签，DMP还需要能够比较灵活地按照网站定义的用户标签来加工受众人群；二、如果媒体网站授权，DMP可以提供接口对加工出来的用户标签进行变现，并与网站进行分成；三、广告主网站可以通过DMP与广告采买渠道进行更方便地数据对接。这一点可以从一个典型的应用来理解：假如某广告主需要通过外部广告平台做重定向(见第7章)，那么需要将自己的用户集合通过某种技术方式通知广告平台。如果每个广告平台都采用在广告主网站上加跟踪代码的方式来收集用户，有两个的弊端，一是多个广告平台同时加代码，有可能使页面变得太重；二是访客的积累需要可能长达数周的时间，这使得广告平台重定向的效率降低。如果由DMP唯一负责广告主网站的用户积累和划分，并通过数据接口的方式传送给广告平台，那么可以极大程度上解决上述问题。

\subsection{DMP架构}

DMP系统的架构可以示意性地表示如下图：通过Data Highway收集各合作媒体或广告主的访问日志，然后把这些日志中的用户信息映射到按照结构化或非结构化的标签体系上。这一架构的核心，是同时对接第三方数据和第一方数据，并根据这些数据对受众群体做灵活的、自定义的划分。虽然这些功能并不直接包括在广告交易环节中，却是数据驱动的在线广告市场中越来越重要的一环。

\begin{figure}
\centering
\scalebox{0.6}
{
    \includegraphics[width=1.65\textwidth]{DMP.eps}
}
\caption{数据管理平台(DMP)系统架构示意}
\end{figure}

除了需要用到上面讨论的受众定向技术，DMP还有一个技术问题，就是如何将加工好的用户标签传送给其他标签的购买方，比如某DSP(见第7章)。虽然在图中我们的示意是直接通过在线cache的形式访问，实际上由于DMP与DSP之间跨域且物理上分开的原因，这样的方案并不实际。因此，在DMP中，往往需要提供数据交换(Data Exchange) 的产品功能，来进行离线的数据对接。

\subsection{DMP案例}

在北美的在线广告市场上，有不少以DMP类似业务为主要方向的公司。在这里我们介绍两家比较有代表性的：一家是Bluekai，一家是AudienceScience。在*图中，后者实际上被划分在“Targeted/Audience”这个板块中，不过由于其主要业务也是面向其它网站的数据加工，因此可以放在DMP板块中加以比较。

\subsubsection{Bluekai}

Bluekai的主要业务模式，是聚合大量中小媒体的有价值行为数据，使用受众定向技术为用户打上标签，并对外售卖标签以获取收入。Bluekai同时提供面向媒体、数据提供商和广告主的一系列产品：包括一个DMP、一个数据交换平台(Bluekai Exchange)、以及一个数据分析系统。这几项产品都围绕一个商业目标展开：那就是帮助有数据变现需求的参与者能够自由、灵活地通过技术对接的方式与广告主进行交易。对于媒体或者其他拥有数据者，可以通过Bluekai Exchange将自己的数据公开式地出售给市场上的需求方，同时可以比较自主地控制定价；对于广告主，可以通过Bluekai提供的DMP产品和第三方数据标签，与自己的第一方数据结合起来，对自己的人群进行更灵活的划分，并按此购买广告。Bluekai通过数据交易获得的收入，其中很大比例还将返还给数据提供方。

通过这种数据交换方式，广告市场上最有价值的数据资源被盘活利用了：数据拥有者不需要直接涉足复杂的广告业务，也可以对数据进行变现；而数据需求者也可以方便地找到数据购买来源，以快速提高自己广告投放的效果。

Bluekai有着比较开放的标签体系，根据广告主使用目的和数据来源的不同，这些标签又分成如下的几种：Intent、B2B、Past Purchases、Geo/Demo、Interest/Lifestyle、Branded、Estimated Financial/Economic。这是一个比较典型的半开放的标签体系，其中的Intent部分，非常类似于前文中的兴趣定向体系，这部分是由Bluekai根据通过Data Exchange收集的用户行为加工的。而其他的部分，有的是由其它数据提供商直接提供，比如由Bizo提供的B2B标签；也有的是根据多家的数据融合决策而成，比如Demo/Geo标签，实际上融合了Bizo、Datalogix、Expedia等多家数据提供商的数据源。

之所以说Bluekai的标签体系是开放式的，是因为它会根据数据的的来源和市场需求不断拓展和调整标签的类别和内容，力求能够满足尽可能多的广告主的特质化需求。Bluekai主要的几种标签、覆盖用户量和主要数据来源，我们列在下表中。
\begin{table}
  \caption{Bluekai标签体系主要类别}
  \begin{center}
    \begin{tabular}{|c|c|c|c|}
      \hline 类别 & 描述 & 数据来源 & 规模(用户数) \\
      \hline Intent             & 最近输入词表现出某种产品或服务需求的用户 & Bluekai Intent & 160+MM\\
      \hline B2B                & 职业上接近某种需求的用户 & Bizo & 12+MM\\
      \hline Past Purchase      & 根据以往消费习惯判断可能购买某产品的用户 & Addthis, Alliant & 65+MM\\
      \hline Geo/Demo           & 地理上或人口属性上接近某标签的用户 & Bizo, Datalogix, Expedia & \\
      \hline Interest/LifeStyle & 可能喜欢某种商品，或某种生活风格的用户 & Forbes, i360, IXI, ... & 103+MM\\
      \hline Estimated Financial& 根据对用户财务状况的估计做的分类 & V12 & \\
      \hline
    \end{tabular}
  \end{center}
  \label{table_exp}
\end{table}

\subsubsection{AudienceScience}

AudienceScience是广告市场上首先明确提出“Audience Targeting”这一概念的公司，并且长期专注于这方面的数据加工和算法建设。

就其数据聚合和收入分成的模式来说，AudienceScience与Bluekai有很多相似之处。两者主要的一个区别，是AudienceScience并不是通过售卖标签来获得收入，而是通过运营一个自有的广告网络来变现。这样做的原因，是AudienceScience认为数据加工业务在扣除媒体分成以后利润空间太小，而自营广告网络有可能获得更大的套利空间。

\clearpage{\pagestyle{empty}} %\cleardoublepage
%\clearpage{\pagestyle{empty}\cleardoublepage}

\end{CJK*}
